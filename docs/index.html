<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Fake It Till You Make It</title>
    <link rel="shortcut icon" type="image/jpg" href="img/favicon.ico" />
    <!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css"> -->
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <script src="https://kit.fontawesome.com/49f46e7382.js" crossorigin="anonymous"></script>

</head>

<body>
    <nav class="navbar is-dark" role="navigation" aria-label="main navigation">
        <div class="container is-max-desktop">
            <div class="navbar-brand">
                <a class="navbar-item" href="https://www.microsoft.com/en-us/research/lab/mixed-reality-ai-lab-cambridge/">
                    <img src="img/Microsoft-logo.svg" alt="Mixed Reality & AI Lab â€“ Cambridge" style="height: 1.4rem;">
                </a>
                <hr class="navbar-divider">
                <a class="navbar-item" href="https://www.microsoft.com/en-us/research/lab/mixed-reality-ai-lab-cambridge/">
                    Mixed Reality & AI
                </a>
                <a class="navbar-item" href="http://iccv2021.thecvf.com/">
                    ICCV 2021
                </a>
            </div>
        </div>

    </nav>
    <section class="section">
        <div class="container is-max-desktop">
            <h1 class="title is-2 has-text-centered">
                Fake It Till You Make It
            </h1>
            <p class="subtitle is-4 has-text-centered">
                Face analysis in the wild using synthetic data alone
            </p>
            <!-- <p class="subtitle is-5 has-text-centered has-text-grey">
                International Conference on Computer Vision (ICCV) 2021
            </p> -->
            <p class="subtitle is-6 has-text-centered authors" style="line-height: 1.5;">
                <span>
                    <!-- alternative ast: &#x1F7B6; -->
                    <a href="mailto:erwood@microsoft.com" class="has-tooltip-bottom" data-tooltip="* denotes equal contribution">Erroll Wood</a><sup>*</sup>
                </span>
                <span>
                    <a href="mailto:tabaltru@microsoft.com" class="has-tooltip-bottom" data-tooltip="* denotes equal contribution">Tadas Baltrusaitis</a><sup>*</sup>
                </span>
                <span>
                    <a>Charlie Hewitt</a>
                </span>
                <span>
                    <a>Sebastian Dziadzio</a>
                </span>
                <span>
                    <a>Matthew Johnson</a>
                </span>
                <span>
                    <a>Virginia Estellers</a>
                </span>
                <span>
                    <a>Thomas J. Cashman</a>
                </span>
                <span>
                    <a>Jamie Shotton</a>
                </span>
            </p>
        </div>
        <!-- </section> -->
        <!-- <section class="section"> -->
        <div class="container is-max-desktop has-text-centered mt-5">
            <!-- <a class="button is-rounded is-link is-light mr-2" disabled>
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                <span>Paper</span>
            </a> -->
            <a class="button is-rounded is-link is-light mr-2" disabled>
                <span class="icon"><i class="ai ai-arxiv"></i></span>
                <span>arXiv</span>
            </a>
            <a href="https://www.youtube.com/watch?v=G4aZZhWmm4k" class="button is-rounded is-link is-light mr-2">
                <span class="icon"><i class="fab fa-youtube"></i></span>
                <span>Video</span>
            </a>
            <a href="https://github.com/microsoft/FaceSynthetics" class="button is-rounded is-link is-light" disabled>
                <span class="icon"><i class="fab fa-github"></i></span>
                <span>Dataset</span>
            </a>
        </div>
    </section>
    <section>
        <div class="container is-max-desktop">
            <figure class="image is-16by9">
                <iframe class="has-ratio" width="640" height="360" src="https://youtube.com/embed/nRp_VQQgcNc" frameborder="0" allowfullscreen></iframe>
            </figure>
        </div>
    </section>
    <section class="section">
        <div class="container is-max-desktop">
            <h1 class="title is-4">
                Abstract
            </h1>
            <div class="content">
                <p>We demonstrate that it is possible to perform face-related computer vision in the wild <strong>using synthetic data alone</strong>.</p>
                <p>
                    The community has long enjoyed the benefits of synthesizing training data with graphics, but the domain gap between real and synthetic data has remained a problem, especially for human faces. Researchers have tried to bridge this gap with data mixing,
                    domain adaptation, and domain-adversarial training, but we show that it is possible to synthesize data with minimal domain gap, so that models trained on synthetic data generalize to real in-the-wild datasets.
                </p>
                <p>
                    We describe how to combine a procedurally-generated parametric 3D face model with a comprehensive library of hand-crafted assets to render training images with unprecedented realism and diversity. We train machine learning systems for face-related tasks
                    such as landmark localization and face parsing, showing that synthetic data can both match real data in accuracy as well as open up new approaches where manual labelling would be impossible.
                </p>
            </div>
        </div>
    </section>
    <section class="section pt-0">
        <div class="container is-max-desktop">
            <h1 class="title is-4">
                Dataset
            </h1>
            <content>
                <figure class="image mb-5">
                    <img src="img/dataset_samples.jpg">
                </figure>
                <p>
                    Our dataset of <strong>100,000 synthetic faces</strong> with 2D landmark and per-pixel segmentation labels will be available to download soon, for non-commercial research purposes. Please watch this space.
                </p>
            </content>
        </div>
    </section>
    <section class="section pt-0">
        <div class="container is-max-desktop">
            <div class="columns">
                <div class="column">
                    <h1 class="title is-5">
                        Face Parsing
                    </h1>
                    <video class="mb-3 is-16by9" width="100%" autoplay muted loop>
                        <source src="video/face_parsing.mp4" type="video/mp4">
                    </video>
                    <p>
                        Pixel-perfect segmentation labels let us achieve near-SOTA results using off-the-shelf neural networks.
                    </p>
                </div>
                <div class="column">
                    <h1 class="title is-5">
                        Dense Landmarks
                    </h1>
                    <video class="mb-3 is-16by9" width="100%" autoplay muted loop>
                        <source src="video/dense_landmarks.mp4" type="video/mp4">
                    </video>
                    <p>
                        With synthetic landmark labels, its easy to predict ten times as many landmarks as usual.
                    </p>
                </div>
            </div>
        </div>
    </section>
    <section class="section pt-0">
        <div class="container is-max-desktop">
            <h1 class="title is-4">
                Method
            </h1>
            <div class="columns is-mobile is-variable is-0-mobile is-0-tablet is-1-desktop is-1-widescreen is-1-fullhd">
                <div class="column"><img src="img/iccv21_process_render_0.png" style="width: 100%;"></div>
                <div class="column"><img src="img/iccv21_process_render_1.png" style="width: 100%;"></div>
                <div class="column"><img src="img/iccv21_process_render_2.png" style="width: 100%;"></div>
                <div class="column"><img src="img/iccv21_process_render_3.png" style="width: 100%;"></div>
                <div class="column"><img src="img/iccv21_process_render_4.png" style="width: 100%;"></div>
                <div class="column"><img src="img/iccv21_process_render_5.png" style="width: 100%;"></div>
                <div class="column"><img src="img/iccv21_process_render_6.png" style="width: 100%;"></div>
            </div>
            <p>
                Our synthetic faces are realistic, diverse, and expressive. Starting with our template face, we randomize the identity, choose a random expression, apply a random texture, and attach random hair and clothing. We finally render the face in a random environment
                using <a href=https://www.cycles-renderer.org>Cycles</a>: a physically-based path tracing renderer.
            </p>
        </div>
    </section>
    <section class="section pt-0">
        <div class="container is-max-desktop">
            <h1 class="title is-4">
                BibTeX
            </h1>
            <pre>
@article{wood2021fakeit
    author  = {Wood, Erroll and Baltrusaitis, Tadas and Hewitt, Charlie and Dziadzio, Sebastian and Cashman, Thomas J. and Shotton, Jamie},
    title   = {Fake it till you make it: Face analysis in the wild using synthetic data alone},
    journal = {ICCV},
    year    = {2021},
}</pre>
        </div>
    </section>
    <footer class="footer">
        <div class="content has-text-centered">
            <p>
                * denotes equal contribution.
            </p>
        </div>
    </footer>
</body>

</html>